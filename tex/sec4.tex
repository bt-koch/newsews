\chapter{News Sentiment Indicator}\label{sec4}
\thispagestyle{empty}

\section{Overview}

As shown in the literature, the sentiment in news articles can be a leading indicator for movements in financial markets. The goal of this analysis is to construct a sentiment indicator from news media articles using a large language model (LLM) to classify the sentiment from a given text. For this analysis, a Bidirectional Encoder Representations from Transformers (BERT) model which was fine-tuned on financial text is used for sentiment classification. Due to its ability to understand the context of words within the rest of the text provided, it is expected that a BERT model performs better in correctly classifying the sentiment of text compared to traditional methods such as bag-of-word algorithms. Using news articles from different sources, a sentiment indicator in daily and weekly frequency is constructed. The goal of this indicator will be to deliver early warning for increased risk of a specific bank. This chapter is structured as follows. First, the preprocessing of news articles and the classification system is described. Then, the method to construct an indicator from the classified sentiment of the news articles is shown. Additionally, the possibility to further classify the articles by topic is presented. The chapter concludes by discussing the benefits and limitations of the constructed indicators.


\section{Step 1: Preprocessing of News Articles} \label{sec:preprocessing}

Depending on the underlying data source used for this study, it is not guaranteed that an article contains relevant information in the context of the research question. Since the articles are queried from the data source by the banks name, its ticker or a common abbreviation, there will be articles in the sample which contain no relevant content about the financial health of the corresponding bank. There might be articles in the sample that, for example, describe a sports event where the corresponding bank is mentioned as a sponsor. Additionally, it is possible that an article covers different topics or different companies and hence only a small part of the article might contain relevant information about the corresponding bank.\\

Hence, to avoid introducing noise through irrelevant content, a rule-based model is applied to identify articles which contain information about the corresponding bank. First, the article is split into its paragraphs. Using pattern matching and predefined identifying patterns for the corresponding bank, we check for each paragraph whether the bank is mentioned in it and remove paragraphs with no occurrence of the banks identifying pattern. Then, again using pattern matching, it is checked whether the content of these paragraphs is relevant from a financial perspective by checking for keywords of a predefined list of economic and financial keywords. We then classify the sentiment as described in section \ref{sec:sentim-classification} only on these remaining paragraphs from the article.

\section{Step 2: Estimate Sentiment of Text} \label{sec:sentim-classification}

Once the preprocessing of the news articles is finished, we have a list of paragraphs extracted from a specific article which we assume contain relevant information about the corresponding bank $b$ at time $t$. Next, for each paragraph, we want to assess whether the sentiment is positive, neutral or negative. For this classification, we use a Bidirectional Encoder Representation from Transaction (BERT) models based on \cite{devlin2019}. \cite{devlin2019} use a masked language model (MLM) and next sentence prediction (NSP) as two unsupervised tasks to train the BERT model. The MLM randomly masks 15\% of tokens in a sentence and predicts the  masked tokens using the remaining tokens in the sentence to obtain a bidirectional pre-trained model, and hence gains the ability to understand the relationship between words in a sentence. To further understand sentence relationships, \cite{devlin2019} pre-train the BERT model with a next sentence prediction task. Hence, the main advantage of using a BERT model in this analysis compared to traditional methods such as lexicon-based models is the ability of the BERT model to understand context. Additionally, fine-tuning a pre-trained BERT model to perform a specific task does not require substantial task-specific modifications of the architecture and is hence relatively easy \citep{devlin2019}. To classify both german and english text, this analysis utilizes a BERT model which was fine-tuned for financial sentiment classification on the corresponding language. Both models are available on \url{https://huggingface.co}. The english model is described in \cite{araci2019} and available on \url{https://huggingface.co/ProsusAI/finbert}. The german model is described in \cite{scherrmann2023} and available on \url{https://huggingface.co/scherrmann/GermanFinBert_SC_Sentiment}. Table \ref{tab:bert-examples} demonstrates the ability of the german BERT model to correctly classify the sentiment of the text given the context.

\begin{table}[H]
\caption{Examples of Sentiment Classification}
\label{tab:bert-examples}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|l|l|}
\hline
input & classification \\ \hline
\textit{\begin{tabular}[c]{@{}l@{}}Diese Neuigkeiten über die schlechte Entwicklung der allgemeinen\\ Wirtschaftslage hat einen beträchtlichen Einfluss auf die Credit Suisse.\end{tabular}}  & negative       \\ \hline
\textit{\begin{tabular}[c]{@{}l@{}}Diese Neuigkeiten über die schlechte Entwicklung der allgemeinen\\ Wirtschaftslage hat keinen beträchtlichen Einfluss auf die Credit Suisse.\end{tabular}} & neutral        \\ \hline
\textit{\begin{tabular}[c]{@{}l@{}}Diese Neuigkeiten über die schlechte Entwicklung der allgemeinen Wirtschafts-\\lage hat einen beträchtlich vorteilhaften Einfluss auf die Credit Suisse.\end{tabular}} & positive       \\ \hline
\end{tabular}%
}
\end{table}

The sentiment $s$ towards bank $b$ at time $t$ of each paragraph $p$ in the article $a$ in this list is classified by the fine-tuned BERT model as follows:

\begin{equation}
s_{b,t,a,p} = \begin{cases}
	-1	& \text{if the paragraph $p$ is classified as negative}\\
	0 	& \text{if the paragraph $p$ is classified as neutral} \\
	1	& \text{if the paragraph $p$ is classified as positive}
\end{cases}
\end{equation}

Both the fine-tuned German and English BERT models were executed locally on a standard consumer laptop, enabling secure processing of sensitive data and practical implementation without requiring special hardware. Hence, these methodologies could be applied within a supervisory process without significant investments in IT infrastructure.

\section{Step 3: Construction of Sentiment Indicator}

After the sentiment of all paragraphs $P$ in article $a$ about bank $b$ at time $t$ is classified as described in section \ref{sec:sentim-classification}, the overall sentiment of article $a$ ($s_{b,t,a}$) is calculated as the arithmetic mean of all corresponding paragraphs $p \in P$. To define the overall sentiment towards bank $b$ at time $t$, the sentiment is further aggregated by the arithmetic mean of the sentiment $s_{b,t,a}$ for all articles $a \in A$ about bank $b$ at time $t$:

 \begin{equation} \label{eq:sentind}
 	s_{b,t} = \frac{1}{A} \sum^A_{a=1} s_{b,t,a} \quad\text{whereby}\quad s_{b,t,a} = \frac{1}{P} \sum^P_{p=1} s_{b,t,a,p}
 \end{equation}
 
 As the literature shows, sentiment scores tend to be noisy, which is why smoothing techniques or aggregation on lower frequency are applied to reduce the noise observed. In this analysis, when working in weekly frequency, we assume that the noise is adequately reduced by aggregating all articles from the corresponding week using the arithmetic mean. We assume that information contained in articles before $t$ remain relevant at time $t$, whereby the relevancy is decreasing over time. When working in weekly frequency, we incorporate this assumption into our models by including lagged values of the sentiment indicator $s_{b,t}$ into our models. However, when working in daily frequency, we construct the sentiment indicator $\tilde{s}_{b,t}$ as a $N$-period backward-looking weighted moving average:
 
\begin{equation} \label{eq:sentind_wma}
	\tilde{s}_{b,t} = \frac{1}{\sum^N_{n=1}n} * \sum^{N-1}_{n=0}(N-n)*s_{b,t-n}
\end{equation}

As a result, we get a weekly and a daily indicator which proxies the sentiment in news articles were $s_{b,t} \in [0,1]$ and $\tilde{s}_{b,t} \in [0,1]$. Values in $[-1,0)$ indicate negative sentiment, $0$ neutral sentiment and $(0,1]$ positive sentiment. Furthermore, we define an adjusted $N$-period backward-looking weighted moving average:\\

\begin{equation} \label{eq_sentind_wma_adj}
	\tilde{s}_{adj,b,t} = \begin{cases}
		0 & \text{if }\tilde{s}_{b,t} > -0.25 \\
		\tilde{s}_{b,t} & \text{otherwise}
	\end{cases}
\end{equation}

This indicator $\tilde{s}_{adj,b,t}$ is a signal for negative sentiment of a sufficient degree only. Sentiment scores which are above the threshold of $-0.25$ are hence classified as neutral.

\section{Additional step: Topic Classification} \label{sec:topicmodelling}

To construct the sentiment indicator, all content which was available after preprocessing as described in section \ref{sec:preprocessing} was used to construct one single indicator. News sentiment can be further categorised by the topic of the content. The results of \cite{roeder2020} suggest, that news sentiment of different topics have different relations to CDS spreads, whereby negative news topics are associated with significant changes in CDS spreads. They also find that not only financial topics but also non-financial topics such as sanctions and legal issues are associated with CDS spread changes. \\

In this additional step, the articles were classified by topic using another BERT model, which was trained for financial topic classification. Again, this model is publicly available on \url{https://huggingface.co/nickmuchi/finbert-tone-finetuned-finance-topic-classification}. This classifier was trained on a dataset with tweets about financial content which have a topic label from a list of 20 different topics. For this study, we focus on bank specific non-financial topics, since this would be a bigger contribution to measures which already proxy the financial market. We classify the topic of article $a$ as follows:

\begin{equation}
	\text{topic}_a = \begin{cases}
		\text{Company, Product News} \\
		\text{Legal, Regulation} \\
		\text{Personnel Change} \\
		\text{other}
	\end{cases}
\end{equation}

This classification was performed once using the title and once using the lead of the article. The lead, usually at the beginning of the article, summarises the key content of the article and can be identified using HTML-tags included in the dataset. Since the BERT model used for this classification was trained on english text, both the title and the lead are translated to english before this classification using a general LLM.

%\begin{equation}
%	\text{topic}_a = \begin{cases}
%		\text{Analyst Update} \\
%		\text{Fed, Central Bank} \\
%		\text{Company, Product News} \\
%		\text{Treasuries, Corporate Debt} \\
%		\text{Dividend} \\
%		\text{Earnings} \\
%		\text{Energy, Oil} \\
%		\text{Financials} \\
%		\text{Currencies} \\
%		\text{General News, Opinion} \\
%		\text{Gold, Metals, Materials} \\
%		\text{IPO} \\
%		\text{Legal, Regulation} \\
%		\text{M\&A, Investments} \\
%		\text{Macro} \\
%		\text{Markets} \\
%		\text{Politics} \\
%		\text{Personnel Change} \\
%		\text{Stock Commentary} \\
%		\text{Stock Movement}
%	\end{cases}
%\end{equation}



\section{Discussion}

One of the main challenges of constructing a sentiment indicator from unstructured text is to determine whether the content within the text is relevant for the specific task. The simple pattern matching decision rule used in this study as described in section \ref{sec:preprocessing} could be further extended to filter out more noise from the indicator. The decision rule as used in this study could be designed more strictly by requiring the surpassing of a predefined quote of matched patterns to total words in the article. However, there is a trade-off between being too strict and filtering too much information or being not strict enough and introducing too much noise in the indicator. Another possibility to reduce the noise in the sentiment are filtering techniques as used in equation \ref{eq:sentind_wma}. There might be other smoothing techniques such as the CUMSUM-filter or the exponential moving average which could perform better in this application. Additionally, the sentiment indicator could also be constructed to consider changes rather than levels in news sentiment by applying crossing moving averages or crossing exponential moving averages. \\

The sentiment classification using a BERT model appears to be promising. Traditional methods for sentiment classification require extensive preprocessing of the text such as word stemming and lemmatising as well as the maintenance of a word list with the associated sentiment. The BERT model used in this study can classify the text successfully without requiring further preprocessing. The main advantage however is the ability of the BERT model to identify the context of words and classifying the sentiment accordingly. As displayed in table \ref{tab:bert-examples}, the model correctly changes the classification of the texts which differ only slightly but contain a different sentiment. \\

The sentiment indicator could be further adjusted by incorporating additional meta information about the article or the publisher of the corresponding article. If available, articles could be weighted by readership figures of the publisher, giving more weight to publications with higher readership. The sentiment indicator could also be adjusted by incorporating the total number of articles published on a given day. An unusually high volume of articles published on a specific day might indicate increased relevance of the information contained in the articles. There might also be differences in the writing styles of publishers that could be leveraged. Some publishers might have a more exaggerated reporting approach, while others might be more neutral. Consequently, if the readers are aware of the corresponding publishers way of reporting, their reactions on articles from different publishers might be different even if the sentiment scores are the same. 

% hier evtl noch das mit business model von medienhäusern



\cleardoublepage
